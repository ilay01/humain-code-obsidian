s# Mögliche Gefährdungen durch KI-Systeme

## Bias and Discrimination
Da sie ihre Erkenntnisse aus den bestehenden Strukturen und Dynamiken der Gesellschaften, die sie analysieren, beziehen, können datengesteuerte Technologien die in diesen Gesellschaften bestehenden Muster der Marginalisierung, Ungleichheit und Diskriminierung reproduzieren, verstärken und vervielfältigen.

Da viele der Merkmale, Metriken und Analysestrukturen der Modelle, die Data Mining durchführen, von ihren Entwicklern ausgewählt werden, können diese Technologien potenziell die Vorurteile und Verzerrungen ihrer Entwickler reproduzieren.

Schließlich können die Datenproben, die zum Trainieren und Testen algorithmischer Systeme verwendet werden, oft nicht ausreichend repräsentativ für die Bevölkerung sein, aus der sie ihre Schlüsse ziehen. Dies birgt die reale Gefahr von voreingenommenen und diskriminierenden Ergebnissen, da die Daten, die in die Systeme eingespeist werden, von vornherein fehlerhaft sind.


## Verweigerung von individueller Autonomie, Regress (?) und Rechten
Wenn Bürger Entscheidungen, Vorhersagen oder Klassifizierungen unterworfen sind, die von KI-Systemen erstellt wurden, können Situationen entstehen, in denen diese Personen nicht in der Lage sind, die für diese Ergebnisse verantwortlichen Parteien direkt zur Rechenschaft zu ziehen.

KI-Systeme automatisieren kognitive Funktionen, die bisher ausschließlich den verantwortlichen menschlichen Akteuren zuzuschreiben waren. Dies kann die Bestimmung der Verantwortung für algorithmisch generierte Ergebnisse erschweren, da der komplexe und verteilte Struktur der Design-, Produktions- und Implementierungsprozesse von KI-Systemen es schwierig machen kann, die verantwortlichen Akteure zu identifizieren.

In Fällen von Verletzungen oder negativen Folgen kann eine solche Verantwortungslücke die Autonomie beeinträchtigen und die Rechte der betroffenen Personen verletzten.

## Intransparente, unerklärliche oder nicht zu rechtfertigende Folgen/ Ergebnisse
Viele Modelle des maschinellen Lernens generieren ihre Ergebnisse, indem sie auf hochdimensionalen Korrelationen basieren, die jenseits der Interpretationsfähigkeiten des menschlichen Denkens liegen. In diesen Fällen bleibt die Logik der algorithmisch erzeugten Ergebnisse, die sich direkt auf die Entscheidungsträger auswirken, für diese unverständlich. Während in einigen Anwendungsfällen dieser Mangel an Erklärbarkeit akzeptabel sein mag, kann in einigen Anwendungen, in denen die verarbeiteten Daten Spuren von Diskriminierung, Verzerrung, Ungleichheit oder Unfairness enthalten könnten, die Intransparenz des Modells äußerst problematisch sein.


## Verletzung der Privatsphäre
Gefährdungen für die Privatsphäre gehen von KI-Systemen sowohl durch ihre Design- und Entwicklungsprozesse als auch durch ihren Einsatz aus. Da KI-Projekte in der Strukturierung und Verarbeitung von Daten verankert sind, wird die Entwicklung von KI-Technologien häufig die Nutzung personenbezogener Daten beinhalten. Diese Daten werden manchmal ohne die ordnungsgemäße Zustimmung der betroffenen Person erfasst und extrahiert oder in einer Weise verarbeitet, die personenbezogene Informationen offenbart (oder das Risiko der Offenbarung von Daten birgt).

Auf der Anwendungsseite könnten KI-Systeme, die auf die betroffenen Personen abzielen, Profile erstellen oder sie ohne ihr Wissen oder ihre Zustimmung beeinflussen, unter Umständen als Eingriff in ihre Fähigkeiten betrachtet werden, ein Privatleben zu führen, in dem sie in der Lage sind, die transformativen Auswirkungen der Technologien, die ihre Entwicklung beeinflussen und gestalten, bewusst zu steuern. Diese Art des Eingriffs in die Privatsphäre kann folglich das grundlegendere Recht einer Person beeinträchtigen, ihre Ziele und Lebenspläne frei von ungewollter Beeinflussung zu verfolgen.


## Isolation und Trennung von sozialen Bindungen
Während die Fähigkeit von KI-Systemen, individuelle Erfahrungen zu kreieren und digitale Dienste zu personalisieren, das Leben der Verbraucher und die Bereitstellung von Diensten erheblich zu verbessern verspricht, birgt dieser Nutzen auch potenzielle Risiken. Eine übermäßige Automatisierung könnte beispielsweise den Bedarf an zwischenmenschlicher Interaktion verringern, während eine algorithmisch ermöglichte Hyper-Personalisierung durch die Einschränkung unseres Kontakts mit anderen Weltanschauungen zu einer Polarisierung der sozialen Beziehungen führen könnte. Gut geordnete und zusammenhängende Gesellschaften bauen auf Beziehungen des Vertrauens, der Empathie und des gegenseitigen Verständnisses auf. Mit der zunehmenden Verbreitung von KI-Technologien ist es wichtig, dass diese Beziehungen erhalten bleiben.


## Unzuverlässige, unsichere oder qualitativ mangelhafte Ergebnisse
Verantwortungsloses Datenmanagement, nachlässige Design- und Produktionsprozesse und fragwürdige Einsatzpraktiken können, jeder auf seine Weise, zur Implementierung und Verbreitung von KI-Systemen führen, die unzuverlässige, unsichere oder qualitativ schlechte Ergebnisse liefern. Diese Ergebnisse können dem Wohlergehen einzelner Personen und dem öffentlichen Wohl direkten Schaden zufügen. Sie können auch das öffentliche Vertrauen in den verantwortungsvollen Einsatz von gesellschaftlich nützlichen KI-Technologien untergraben und sie können schädliche Ineffizienzen schaffen, indem sie begrenzte öffentliche Ressourcen für ineffiziente oder sogar schädliche KI-Technologien einsetzen.

( den letzten Teil habe selbst ich nicht wirklich verstanden)

Alles aus dem Paper bzw PDF [[Understanding artificial intelligence ethics and safety, the alan turing institute]]
